#  Seq2Seq Transliteration with Attention ‚Äî Aksharantar (IIT Madras)

**Romanized ‚Üí Devanagari transliteration** using a character-level Seq2Seq model with **LSTM + Bahdanau Attention**.  
This repo is a compact, well-documented, and reproducible solution prepared for the IIT Madras Technical Aptitude challenge.

---

##  Quick summary
- **Task:** Map romanized character sequences (e.g., `ghar`) ‚Üí native script (e.g., `‡§ò‡§∞`).  
- **Model:** Encoder (LSTM) + Decoder (LSTM) with Bahdanau additive attention.  
- **Language:** Python + PyTorch. Ready to run on Colab GPU.

---

##  Repo structure (what's important)
```
Seq2Seq-Aksharantar-IITM/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ encoder.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ decoder.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ attention.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ seq2seq.py
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dataset.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ metrics.py
‚îÇ       ‚îî‚îÄ‚îÄ training_loop.py
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ model_config.yaml
‚îÇ   ‚îî‚îÄ‚îÄ data_config.yaml
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ Transliteration_Report.ipynb
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ raw/sample.tsv
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## üß© Architecture (ASCII diagram)
```
      Input (Romanized) chars
               ‚îÇ
         [Embedding Layer]
               ‚îÇ
         [LSTM Encoder]  -> encoder outputs (sequence of h vectors)
               ‚îÇ
               ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ                   ‚ñº
            (enc outputs)    Bahdanau Attention
               ‚îÇ                   ‚îÇ
               ‚îÇ                   ‚ñº
            (context vector) ‚îÄ‚îÄ> [LSTM Decoder] (uses prev token + context)
                                     ‚îÇ
                                  [Linear]
                                     ‚îÇ
                                  Softmax
                                     ‚îÇ
                                  Output char
```

---

## ‚öôÔ∏è Default Configs (chosen for Colab & IITM)
- `embedding_size = 128`  
- `hidden_size = 256`  
- `rnn_cell = LSTM`  
- `use_attention = true`  
- `num_layers = 1`  
- `dropout = 0.2`  
- `batch_size = 64`  
- `learning_rate = 0.001`

You can change these in `config/model_config.yaml`.

---

##  Math (Answer to assignment questions ‚Äî explicit & worked example)

### Notation
- `e` = embedding dimension  
- `h` = hidden dimension (encoder & decoder)  
- `T` = input/output sequence length (assumed equal for derivation)  
- `V` = vocabulary size (same for source & target)  
- Single-layer encoder and decoder (adjust multipliers for multiple layers)

### Parameter count (vanilla RNN symbolic)
\[
P_\text{total} = 2Ve + 2(eh + h^2 + h) + hV + V
\]
(Embeddings + encoder RNN + decoder RNN + output projection)

### Computation (dominant matmuls) ‚Äî forward pass
\[
\text{Matmuls} = T \cdot (2eh + 2h^2 + hV)
\]
Multiply by 2 for multiply+add FLOPs. Training (~backprop) ‚âà √ó3 forward cost.

### Worked numeric example
Use `e=128`, `h=256`, `V=5000`, `T=20`:

- Parameters ‚âà **2,762,120** (‚âà 10.5 MB in float32)  
- Forward matmuls ‚âà **29,532,160** ‚Üí ‚âà **59M FLOPs** (multiply+add)

(Full derivation and LSTM/GRU variants are in `notebooks/Transliteration_Report.ipynb`.)

---

##  How to run (quick)
1. Install requirements:
```bash
pip install -r requirements.txt
```

2. Quick smoke test (uses tiny sample shipped in `data/raw/sample.tsv`):
```bash
python scripts/train.py --config config/model_config.yaml --quick_test
```

3. Full training:
```bash
python scripts/train.py --config config/model_config.yaml --out_dir checkpoints
```

4. Evaluate a checkpoint:
```bash
python scripts/evaluate.py --config config/model_config.yaml --checkpoint checkpoints/best.pt
```

---

## üìä Notebook & Visualizations
Open `notebooks/Transliteration_Report.ipynb` to see:
- Architecture explanation
- Mathematical derivation (step-by-step)
- Attention visualization sketch (heatmaps) and sample outputs

### Training Visualizations
| Loss Curve | Accuracy Curve |
|-------------|----------------|
| ![Loss Curve](scripts/checkpoints/checkpoints/visualizations/
/loss_curve.png) | ![Accuracy Curve](scripts/checkpoints/checkpoints/visualizations/
/accuracy_curve.png) |



---

## üßæ References & Acknowledgements
- AI4Bharat ‚Äî Aksharantar dataset  
- Bahdanau et al. (2014) ‚Äî Neural Machine Translation by Jointly Learning to Align and Translate  
- PyTorch Seq2Seq tutorial

---

## üë©‚Äçüíª Author
Prepared for IIT Madras Technical Aptitude Challenge by **Navyashree N**.

---
